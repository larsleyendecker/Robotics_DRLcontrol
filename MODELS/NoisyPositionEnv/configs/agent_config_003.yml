algorithm : "PPO"
num_cpus : 11
num_gpus : 1
stop :
    episode_reward_mean: 1000
config :
    env : "NoisyPositionEnv"
    SEED : 1794
    num_workers : 10
    num_envs_per_worker : 1
    num_gpus : 1
    #num_cpus_per_worker : 1
    gamma : 0.99
    horizon : 400
    soft_horizon : False
    learning_rate : 0.0001
    train_batch_size : 2500 #250 * num_workers
    model :
        fcnet_hiddens : [256, 256]
        use_lstm : False
        lstm_cell_size : 128
        custom_model : None
        custom_model_config : None
        custom_action_dist : None
        custom_preprocessor : None
    tf_session_args: 
        allow_soft_placement : True
    explore : True
restore : Null
checkpoint_freq : 25
keep_checkpoints_num : Null